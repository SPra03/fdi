{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["8M2rKZzCzWTk"],"authorship_tag":"ABX9TyNAr8ytcmRS9NnwHDKXVwWx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Installations and pre-requisits"],"metadata":{"id":"8M2rKZzCzWTk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8Flvt4tzJfN","executionInfo":{"status":"ok","timestamp":1692817837884,"user_tz":420,"elapsed":20187,"user":{"displayName":"Sourabh Prakash","userId":"03936934707781620921"}},"outputId":"b2b1f2c9-baf7-4970-fb00-704331c0c795"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/FDI/ODC_SCI/Frictionless\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/FDI/ODC_SCI/Frictionless"]},{"cell_type":"code","source":["pip install Frictionless"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hne0LgyxzPhy","executionInfo":{"status":"ok","timestamp":1692817286649,"user_tz":420,"elapsed":24630,"user":{"displayName":"Sourabh Prakash","userId":"03936934707781620921"}},"outputId":"8ec2e878-53ea-41b5-8514-86c85b946c75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Frictionless\n","  Downloading frictionless-5.15.10-py3-none-any.whl (309 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.9/309.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (23.1.0)\n","Requirement already satisfied: chardet>=3.0 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (5.2.0)\n","Requirement already satisfied: humanize>=4.2 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (4.7.0)\n","Collecting isodate>=0.6 (from Frictionless)\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (3.1.2)\n","Collecting jsonschema<4.18 (from Frictionless)\n","  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marko>=1.0 (from Frictionless)\n","  Downloading marko-2.0.0-py3-none-any.whl (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting petl>=1.6 (from Frictionless)\n","  Downloading petl-1.7.14.tar.gz (411 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.7/411.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (2.2.0)\n","Requirement already satisfied: python-dateutil>=2.8 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (2.8.2)\n","Requirement already satisfied: python-slugify>=1.2 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (8.0.1)\n","Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (6.0.1)\n","Requirement already satisfied: requests>=2.10 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (2.31.0)\n","Collecting rfc3986>=1.4 (from Frictionless)\n","  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n","Collecting simpleeval>=0.9.11 (from Frictionless)\n","  Downloading simpleeval-0.9.13-py2.py3-none-any.whl (15 kB)\n","Collecting stringcase>=1.2 (from Frictionless)\n","  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (0.9.0)\n","Requirement already satisfied: typer[all]>=0.5 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (0.9.0)\n","Requirement already satisfied: typing-extensions>=4.3 in /usr/local/lib/python3.10/dist-packages (from Frictionless) (4.7.1)\n","Collecting validators>=0.18 (from Frictionless)\n","  Downloading validators-0.21.2-py3-none-any.whl (25 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate>=0.6->Frictionless) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0->Frictionless) (2.1.3)\n","Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18->Frictionless)\n","  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->Frictionless) (0.5.0)\n","Requirement already satisfied: pydantic-core==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->Frictionless) (2.6.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify>=1.2->Frictionless) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10->Frictionless) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10->Frictionless) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10->Frictionless) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10->Frictionless) (2023.7.22)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]>=0.5->Frictionless) (8.1.7)\n","Collecting colorama<0.5.0,>=0.4.3 (from typer[all]>=0.5->Frictionless)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]>=0.5->Frictionless)\n","  Downloading shellingham-1.5.3-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]>=0.5->Frictionless) (13.5.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]>=0.5->Frictionless) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]>=0.5->Frictionless) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]>=0.5->Frictionless) (0.1.2)\n","Building wheels for collected packages: petl, stringcase\n","  Building wheel for petl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for petl: filename=petl-1.7.14-py3-none-any.whl size=229615 sha256=5206959458ecd0645dfb1bcead24d7dc9b2e7627e115895f1da36ac8b570f41d\n","  Stored in directory: /root/.cache/pip/wheels/65/d2/2c/655203aaf0c828a0b7481dfc3354814dd1b864f4c4b0a413a7\n","  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3570 sha256=5f09702e2aa613117c1f4447ffc48e2c857da81fd91bec9393145c452ec9347f\n","  Stored in directory: /root/.cache/pip/wheels/31/ba/22/1a2d952a9ce8aa86e42fda41e2c87fdaf20e238c88bf8df013\n","Successfully built petl stringcase\n","Installing collected packages: stringcase, simpleeval, validators, shellingham, rfc3986, pyrsistent, petl, marko, isodate, colorama, jsonschema, Frictionless\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 4.19.0\n","    Uninstalling jsonschema-4.19.0:\n","      Successfully uninstalled jsonschema-4.19.0\n","Successfully installed Frictionless-5.15.10 colorama-0.4.6 isodate-0.6.1 jsonschema-4.17.3 marko-2.0.0 petl-1.7.14 pyrsistent-0.19.3 rfc3986-2.0.0 shellingham-1.5.3 simpleeval-0.9.13 stringcase-1.2.0 validators-0.21.2\n"]}]},{"cell_type":"code","source":["!pip install datapackage"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFQKspMHzsQR","executionInfo":{"status":"ok","timestamp":1692817315403,"user_tz":420,"elapsed":28757,"user":{"displayName":"Sourabh Prakash","userId":"03936934707781620921"}},"outputId":"5aa915f4-f875-4efa-8c2c-b23f4d74640c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datapackage\n","  Downloading datapackage-1.15.2-py2.py3-none-any.whl (85 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61.4/85.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from datapackage) (1.16.0)\n","Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.10/dist-packages (from datapackage) (8.1.7)\n","Requirement already satisfied: chardet>=3.0 in /usr/local/lib/python3.10/dist-packages (from datapackage) (5.2.0)\n","Requirement already satisfied: requests>=2.8 in /usr/local/lib/python3.10/dist-packages (from datapackage) (2.31.0)\n","Requirement already satisfied: jsonschema>=2.5 in /usr/local/lib/python3.10/dist-packages (from datapackage) (4.17.3)\n","Collecting unicodecsv>=0.14 (from datapackage)\n","  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jsonpointer>=1.10 (from datapackage)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Collecting tableschema>=1.12.1 (from datapackage)\n","  Downloading tableschema-1.20.2-py2.py3-none-any.whl (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tabulator>=1.29 (from datapackage)\n","  Downloading tabulator-1.53.5-py2.py3-none-any.whl (72 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.5->datapackage) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.5->datapackage) (0.19.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8->datapackage) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8->datapackage) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8->datapackage) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8->datapackage) (2023.7.22)\n","Collecting cached-property>=1.5 (from tableschema>=1.12.1->datapackage)\n","  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from tableschema>=1.12.1->datapackage) (2.8.2)\n","Requirement already satisfied: isodate>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from tableschema>=1.12.1->datapackage) (0.6.1)\n","Requirement already satisfied: rfc3986>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tableschema>=1.12.1->datapackage) (2.0.0)\n","Collecting boto3>=1.9 (from tabulator>=1.29->datapackage)\n","  Downloading boto3-1.28.32-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ijson>=3.0.3 (from tabulator>=1.29->datapackage)\n","  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonlines>=1.1 (from tabulator>=1.29->datapackage)\n","  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n","Requirement already satisfied: sqlalchemy>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from tabulator>=1.29->datapackage) (2.0.20)\n","Collecting linear-tsv>=1.0 (from tabulator>=1.29->datapackage)\n","  Downloading linear-tsv-1.1.0.tar.gz (9.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: xlrd>=1.0 in /usr/local/lib/python3.10/dist-packages (from tabulator>=1.29->datapackage) (2.0.1)\n","Requirement already satisfied: openpyxl>=2.6 in /usr/local/lib/python3.10/dist-packages (from tabulator>=1.29->datapackage) (3.1.2)\n","Collecting botocore<1.32.0,>=1.31.32 (from boto3>=1.9->tabulator>=1.29->datapackage)\n","  Downloading botocore-1.31.32-py3-none-any.whl (11.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.9->tabulator>=1.29->datapackage)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0 (from boto3>=1.9->tabulator>=1.29->datapackage)\n","  Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.1.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=0.9.6->tabulator>=1.29->datapackage) (4.7.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=0.9.6->tabulator>=1.29->datapackage) (2.0.2)\n","Collecting urllib3<3,>=1.21.1 (from requests>=2.8->datapackage)\n","  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: unicodecsv, linear-tsv\n","  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10745 sha256=d95867209d5690426887badc58b81bf9657c0ee474e6ccd7120b466e06ad5705\n","  Stored in directory: /root/.cache/pip/wheels/9c/ea/66/8e45247b09052a933eb1a680b7c64802298faba58aac9b346b\n","  Building wheel for linear-tsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for linear-tsv: filename=linear_tsv-1.1.0-py3-none-any.whl size=7382 sha256=921cd33e2ef5ac3fd0f33a5defb380b559d5a7bb4c950f490ae21d124e1d1178\n","  Stored in directory: /root/.cache/pip/wheels/23/48/78/150e3d7e444b9950aca72218794076a117b6b6afa3d5f077a0\n","Successfully built unicodecsv linear-tsv\n","Installing collected packages: unicodecsv, ijson, cached-property, urllib3, linear-tsv, jsonpointer, jsonlines, jmespath, botocore, s3transfer, boto3, tabulator, tableschema, datapackage\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.4\n","    Uninstalling urllib3-2.0.4:\n","      Successfully uninstalled urllib3-2.0.4\n","Successfully installed boto3-1.28.32 botocore-1.31.32 cached-property-1.5.2 datapackage-1.15.2 ijson-3.2.3 jmespath-1.0.1 jsonlines-3.1.0 jsonpointer-2.4 linear-tsv-1.1.0 s3transfer-0.6.2 tableschema-1.20.2 tabulator-1.53.5 unicodecsv-0.14.1 urllib3-1.26.16\n"]}]},{"cell_type":"code","source":["pip install requests\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltGphOn5Dzxh","executionInfo":{"status":"ok","timestamp":1692817326574,"user_tz":420,"elapsed":11189,"user":{"displayName":"Sourabh Prakash","userId":"03936934707781620921"}},"outputId":"d968577c-7150-4927-865f-af47c27c906f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"]}]},{"cell_type":"markdown","source":["# Script"],"metadata":{"id":"yEOTjQUazg6N"}},{"cell_type":"code","source":["from datapackage import Package, Resource\n","import pandas as pd\n","import requests"],"metadata":{"id":"BWKDF0mzzgX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://odc-sci.org/php/odc-file-download.php?cid=97&type=doi&key=ea96ff7a4078f819a6f333e490803c6f45d02432c7cfb2f5a95a7fffc92c58e7&doi=odc-sci_824\n","\n","# https://odc-sci.org/php/odc-file-download.php?cid=97&type=dict&key=ea96ff7a4078f819a6f333e490803c6f45d02432c7cfb2f5a95a7fffc92c58e7&doi=odc-sci_824"],"metadata":{"id":"ar6QZSogOpFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_type_mapping = {\"Categorical\":\"string\", \"Numeric\":\"number\",\"Free text\":\"string\", }\n","def extract_fields_from_csv(csv_file_path, required_fields):\n","    # Read the CSV file into a DataFrame\n","    data_dictionary = pd.read_csv(csv_file_path, encoding='utf-8', engine='python')\n","\n","    # Create a list to store field data structures\n","    fields = []\n","\n","    # Iterate over each row in the DataFrame\n","    for index, row in data_dictionary.iterrows():\n","        # Create a dictionary for the row\n","        row_data = {}\n","\n","        # Iterate over each column in the row\n","        for col_name in data_dictionary.columns:\n","            # Add the column name and value to the dictionary\n","            if pd.isna(row[col_name]):\n","                # If the value is empty, fill it with None\n","                row_data[col_name] = None\n","            else:\n","                row_data[col_name] = row[col_name]\n","\n","        # Check if the VariableName is in the required fields\n","        if row['VariableName'] in required_fields:\n","            row_data['Required'] = True\n","        else:\n","            row_data['Required'] = False\n","\n","        # mapping the data type from the data dictionary to json data types(used by frictionless)\n","        if row['DataType'] in data_type_mapping.keys():\n","          row_data['type'] = data_type_mapping[row['DataType']]\n","        else:\n","          row_data['type'] = \"any\"\n","\n","        row_data['format'] = \"default\"\n","\n","        # Append the row dictionary to the list of data\n","        fields.append(row_data)\n","\n","    return fields\n","\n","# Example usage:\n","required_fields = [\"Subject_ID\", \"Species\", \"Strain\", \"Animal_origin\", \"Age\", \"Weight\", \"Sex\", \"Group\", \"Laboratory\",\n","                   \"StudyLeader\", \"Published\", \"Exclusion_in_origin_study\", \"Exclusion_reason\", \"Cause_of_Death\",\n","                   \"Injury_type\", \"Injury_device\", \"Injury_level\", \"Injury_details\"]\n","\n","csv_file_path = \"odc-sci_824/odc-sci_824_dictionary.csv\"\n","fields_data = extract_fields_from_csv(csv_file_path, required_fields)\n","\n","# Print the extracted fields data\n","# for field in fields_data:\n","#     print(field)\n"],"metadata":{"id":"WeIGyATZLIwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["package = Package()\n","package.infer(\"odc-sci_824/odc-sci_824.csv\")\n","package.infer(\"odc-sci_824/odc-sci_824_dictionary.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3XNJ3LJ-nEl","executionInfo":{"status":"ok","timestamp":1692826354094,"user_tz":420,"elapsed":1864,"user":{"displayName":"Sourabh Prakash","userId":"03936934707781620921"}},"outputId":"32e2d979-4cc3-43ab-c6f1-c74104746e08"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'profile': 'tabular-data-package',\n"," 'resources': [{'path': 'odc-sci_824/odc-sci_824.csv',\n","   'profile': 'tabular-data-resource',\n","   'name': 'odc-sci_824',\n","   'format': 'csv',\n","   'mediatype': 'text/csv',\n","   'encoding': 'utf-8',\n","   'schema': {'fields': [{'name': 'Subject_ID',\n","      'type': 'string',\n","      'format': 'default'},\n","     {'name': 'Species', 'type': 'string', 'format': 'default'},\n","     {'name': 'Strain', 'type': 'string', 'format': 'default'},\n","     {'name': 'Animal_origin', 'type': 'string', 'format': 'default'},\n","     {'name': 'Age', 'type': 'integer', 'format': 'default'},\n","     {'name': 'Weight', 'type': 'string', 'format': 'default'},\n","     {'name': 'Sex', 'type': 'string', 'format': 'default'},\n","     {'name': 'Group', 'type': 'string', 'format': 'default'},\n","     {'name': 'Laboratory', 'type': 'string', 'format': 'default'},\n","     {'name': 'StudyLeader', 'type': 'string', 'format': 'default'},\n","     {'name': 'Published', 'type': 'string', 'format': 'default'},\n","     {'name': 'Exclusion_in_origin_study',\n","      'type': 'string',\n","      'format': 'default'},\n","     {'name': 'Exclusion_reason', 'type': 'string', 'format': 'default'},\n","     {'name': 'Cause_of_Death', 'type': 'string', 'format': 'default'},\n","     {'name': 'Injury_type', 'type': 'string', 'format': 'default'},\n","     {'name': 'Injury_device', 'type': 'string', 'format': 'default'},\n","     {'name': 'Injury_level', 'type': 'string', 'format': 'default'},\n","     {'name': 'Injury_details', 'type': 'string', 'format': 'default'},\n","     {'name': 'ISI_Vib', 'type': 'integer', 'format': 'default'},\n","     {'name': 'Vib_Hreflex', 'type': 'number', 'format': 'default'},\n","     {'name': 'Time_of_bin_Vib', 'type': 'integer', 'format': 'default'},\n","     {'name': 'PSF_Vib', 'type': 'number', 'format': 'default'},\n","     {'name': 'PSTH_Vib', 'type': 'number', 'format': 'default'},\n","     {'name': 'EMG_Vib', 'type': 'number', 'format': 'default'},\n","     {'name': 'ISI_CFN', 'type': 'integer', 'format': 'default'},\n","     {'name': 'CFN_1.0xMT_Hreflex', 'type': 'number', 'format': 'default'},\n","     {'name': 'CFN_1.5xMT_Hreflex', 'type': 'number', 'format': 'default'},\n","     {'name': 'CFN_facilitation_Hreflex',\n","      'type': 'string',\n","      'format': 'default'},\n","     {'name': 'RDD_percent_change', 'type': 'number', 'format': 'default'},\n","     {'name': 'MU_CFN_1.5xMT_at_ISI', 'type': 'number', 'format': 'default'},\n","     {'name': 'EMG_CFN_1.5xMT_at_ISI', 'type': 'number', 'format': 'default'},\n","     {'name': 'Time_of_bin_CFN', 'type': 'integer', 'format': 'default'},\n","     {'name': 'PSF_CFN_1.0xMT', 'type': 'number', 'format': 'default'},\n","     {'name': 'PSF_CFN_1.5xMT', 'type': 'number', 'format': 'default'},\n","     {'name': 'PSF_CFN_facilitation', 'type': 'string', 'format': 'default'},\n","     {'name': 'PSTH_CFN_1.0xMT', 'type': 'number', 'format': 'default'},\n","     {'name': 'PSTH_CFN_1.5xMT', 'type': 'number', 'format': 'default'},\n","     {'name': 'PSTH_CFN_facilitation', 'type': 'string', 'format': 'default'},\n","     {'name': 'EMG_CFN_1.0xMT', 'type': 'number', 'format': 'default'},\n","     {'name': 'EMG_CFN_1.5xMT', 'type': 'number', 'format': 'default'},\n","     {'name': 'CFN_intensity', 'type': 'number', 'format': 'default'},\n","     {'name': 'Early_MU_area', 'type': 'number', 'format': 'default'},\n","     {'name': 'Hreflex_number', 'type': 'integer', 'format': 'default'},\n","     {'name': 'RDD_2500_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'RDD_2000_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'RDD_1500_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'RDD_1000_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'RDD_500_change_Hreflex', 'type': 'number', 'format': 'default'},\n","     {'name': 'CFN_2500_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'CFN_2000_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'CFN_1500_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'CFN_1000_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'},\n","     {'name': 'CFN_500_change_Hreflex',\n","      'type': 'number',\n","      'format': 'default'}],\n","    'missingValues': ['']}},\n","  {'path': 'odc-sci_824/odc-sci_824_dictionary.csv',\n","   'profile': 'tabular-data-resource',\n","   'name': 'odc-sci_824_dictionary',\n","   'format': 'csv',\n","   'mediatype': 'text/csv',\n","   'encoding': 'utf-8',\n","   'schema': {'fields': [{'name': 'VariableName',\n","      'type': 'string',\n","      'format': 'default'},\n","     {'name': 'Title', 'type': 'string', 'format': 'default'},\n","     {'name': 'Unit_of_Measure', 'type': 'string', 'format': 'default'},\n","     {'name': 'Description', 'type': 'string', 'format': 'default'},\n","     {'name': 'DataType', 'type': 'string', 'format': 'default'},\n","     {'name': 'PermittedValues', 'type': 'string', 'format': 'default'},\n","     {'name': 'MinimumValue', 'type': 'number', 'format': 'default'},\n","     {'name': 'MaximumValue', 'type': 'number', 'format': 'default'},\n","     {'name': 'Comments', 'type': 'string', 'format': 'default'}],\n","    'missingValues': ['']}}]}"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["# package = Package()\n","# package.infer(\"odc-sci_824_datapackage/data/odc-sci_824.csv\")\n","# package.infer(\"odc-sci_824_datapackage/data/odc-sci_824_dictionary.csv\")"],"metadata":{"id":"mBu02xn-_raF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# doi = \"10.34945/F5m88z\"           # 824\n","doi = \"10.34945/F5730S\"             # 851\n","\n","# https://api.datacite.org/dois/10.34945/F5730S\n","# doi = input(\"Enter DOI to create data package:\")\n","# We need to replace this with the DOI you want to retrieve\n","\n","\n","# Constructing the URL with the DOI variable\n","url = f\"https://api.datacite.org/dois/{doi}\"\n","\n","# HTTP GET request to the URL\n","response = requests.get(url)\n","\n","# Checkinng if the request was successful (status code 200)\n","if response.status_code == 200:\n","    # Parseing the JSON response, since the data is in json format\n","    data = response.json()\n","else:\n","    print(f\"Request failed with status code {response.status_code}\")\n"],"metadata":{"id":"gVF1f1CfDgTr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class attributeProcessor:\n","    def __init__(self, data):\n","        self.data = data.get('data', {}).get('attributes', {})\n","\n","    def get_abstract(self):\n","        try:\n","          abstract = self.data.get('descriptions', [{}])[0].get('description', \"\")\n","        except:\n","          abstract=\"\"\n","\n","        if len(abstract) < 1:\n","            return [{\n","                \"STUDY PURPOSE\": \"\",\n","                \"DATA COLLECTED\": \"\"\n","            }]\n","\n","        study_purpose_start = abstract.find(\"STUDY PURPOSE:\") + len(\"STUDY PURPOSE:\")\n","        data_collected_start = abstract.find(\"DATA COLLECTED:\") + len(\"DATA COLLECTED:\")\n","        data_usage_notes_start = abstract.find(\"DATA USAGE NOTES:\") + len(\"DATA USAGE NOTES:\")\n","\n","        study_purpose = abstract[study_purpose_start:data_collected_start - len(\"DATA COLLECTED:\") - 1]\n","        data_collected = abstract[data_collected_start:data_usage_notes_start - len(\"DATA USAGE NOTES:\") - 1]\n","        data_usage_notes = abstract[data_usage_notes_start:]\n","\n","        return [{\n","            \"STUDY PURPOSE\": study_purpose.strip(),\n","            \"DATA COLLECTED\": data_collected.strip()\n","        }]\n","\n","    def get_keywords(self):\n","        keyword_list = self.data.get('subjects', [])\n","        return [keyword['subject'] for keyword in keyword_list]\n","\n","    def get_contributors(self):\n","        contributors_list = self.data.get('creators', [])\n","        formatted_list = []\n","\n","        for contributor in contributors_list:\n","            formatted_item = f\"{contributor['name']} {', '.join(contributor['affiliation'])}\"\n","            formatted_list.append(formatted_item)\n","\n","        return formatted_list\n","\n","    def get_funding_acknowledgement(self):\n","\n","      funders_lst=[]\n","      try:\n","        funding_dict = self.data.get('fundingReferences', [{}])\n","      except:\n","        return[{\n","          'Name': \"\",\n","          'Identifier': \"\",\n","          'Type': \"\"\n","        }]\n","\n","      for funders in funding_dict:\n","        funder =  {\n","          'Name': funders.get('funderName', ''),\n","          'Identifier': funders.get('funderIdentifier', ''),\n","          'Type': funders.get('funderIdentifierType', '')\n","          }\n","        funders_lst.append(funder)\n","\n","      return funders_lst\n","\n","\n","    def get_title(self):\n","        return self.data.get('titles', [{}])[0].get('title', '')\n","\n","    def get_doi(self):\n","        return self.data.get('doi', '')\n","\n","\n","    def get_license(self):\n","\n","      license_lst=[]\n","      try:\n","        license_dict = self.data.get('rightsList', [{}])\n","      except:\n","        return[{\n","          'Name': \"\"\n","        }]\n","\n","      for licenses in license_dict:\n","        license =  {\n","          'Name': licenses.get('rights', '')\n","          }\n","        license_lst.append(license)\n","\n","      return license_lst\n","\n","    # def get_license(self):\n","    #     return [{\"Name\":self.data.get('rightsList', [{}])[0].get('rights', '')}]"],"metadata":{"id":"nRWdVUstC0OL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # adding other details-> meta data\n","\n","att_processor = attributeProcessor(data)\n","\n","package.descriptor[\"title\"] = att_processor.get_title()\n","package.descriptor[\"profile\"] = \"data-package\"\n","package.descriptor[\"DOI\"] = att_processor.get_doi()\n","package.descriptor[\"ABSTRACT\"] = att_processor.get_abstract()\n","package.descriptor[\"KEYWORDS\"] = att_processor.get_keywords()\n","package.descriptor[\"LICENSE\"] = att_processor.get_license()\n","package.descriptor[\"FUNDING AND ACKNOWLEDGEMENTS\"] = att_processor.get_funding_acknowledgement()\n","package.descriptor[\"CONTRIBUTORS\"] = att_processor.get_contributors()"],"metadata":{"id":"W4i9e6uOI-lG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# adding data schema details\n","package.descriptor['resources'][0]['schema']['fields'] = fields_data"],"metadata":{"id":"kYMEhbQZKV3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# package.descriptor"],"metadata":{"id":"DRupVgCA8rsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","  prefix = \"_\".join(data.get('data', {}).get('attributes', {}).get('identifiers',{})[0].get('identifier',{}).split(\":\"))\n","  file_name = prefix+\"_datapackage.zip\"\n","except:\n","  print(\"Error while generating filename, check data idenfifiers\")"],"metadata":{"id":"gKAl57iFydr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["package.commit()\n","print(f\"Saving data package as {file_name}\")\n","package.save(file_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QsWdGvCtKV-h","executionInfo":{"status":"ok","timestamp":1692826364684,"user_tz":420,"elapsed":583,"user":{"displayName":"Sourabh Prakash","userId":"03936934707781620921"}},"outputId":"c3a9708a-2756-4218-cdfc-3e3fcbb7bddf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving data package as odc-sci_851_datapackage.zip\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["# # adding other details-> meta data\n","\n","# att_processor = attributeProcessor(data)\n","# package.descriptor[\"title\"] = att_processor.get_title()\n","# package.descriptor[\"profile\"] = \"data-package\"\n","# package.descriptor[\"DOI\"] = att_processor.get_doi()\n","\n","\n","# # Add DATASET INFO ????  get it from troy, will see later\n","# # package.descriptor[\"DATASET INFO\"] = [\n","# #     {\n","# #         \"Contact\": \"Gorassini Monica (mag4@ualberta.ca)\",\n","# #         \"Lab\": \"Gorassini\",\n","# #         \"ODC-SCI Accession\": \"824\",\n","# #         \"Records in Dataset\": \"1067\",\n","# #         \"Fields per Record\": \"53\",    ADD FROM THE CSV FRILE\n","# #         \"Last updated\": \"2023-02-10\",      # USE UPDATED FOR NOW\n","# #         \"Date published\": \"2023-02-10\",    # NEED TO FIGURE OUT\n","# #         \"Downloads\": \"5\",\n","# #         \"Files\": \"2\"\n","# #     }\n","# # ]\n","\n","# # Add ABSTRACT   # weil have to look into conclusion at publication side,\n","# package.descriptor[\"ABSTRACT\"] = att_processor.get_abstract()\n","\n","# #?? it has description type as well. So my question is are there other types or only anstract. Cz the data processing would change depending upon the type.\n","# # what about conclusion ???? done ->  need to see where the conclusion is\n","\n","# package.descriptor[\"KEYWORDS\"] = att_processor.get_keywords()\n","\n","\n","# # Add PROVENANCE/ORIGINATING PUBLICATIONS  ??\n","# #package.descriptor[\"PROVENANCE/ORIGINATING PUBLICATIONS\"] = [\". doi:10.34945/F5WS3Q.\"]\n","\n","\n","# # relatedIdentifiers ALSO HAS LINKS\n","\n","\n","\n","# package.descriptor[\"LICENSE\"] = att_processor.get_license()\n","# package.descriptor[\"FUNDING AND ACKNOWLEDGEMENTS\"] = att_processor.get_funding_acknowledgement()\n","# package.descriptor[\"CONTRIBUTORS\"] = att_processor.get_contributors()\n","\n","\n","# # Add RELEVANT LINKS\n","# # package.descriptor[\"RELEVANT LINKS\"] = []         # ??? DONT WORRY ABOUT IT\n","\n","# # Add Notes\n","# # package.descriptor[\"Notes\"] = \"....\"   # ????    ## DONT WORRY ABOUT IT"],"metadata":{"id":"8X_wq7S-c9DO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datapackage import Package, Resource\n","import pandas as pd\n","import requests\n","\n","data_type_mapping = {\"Categorical\":\"string\", \"Numeric\":\"number\",\"Free text\":\"string\", }\n","def extract_fields_from_csv(csv_file_path, required_fields):\n","    # Read the CSV file into a DataFrame\n","    data_dictionary = pd.read_csv(csv_file_path, encoding='utf-8', engine='python')\n","\n","    # Create a list to store field data structures\n","    fields = []\n","\n","    # Iterate over each row in the DataFrame\n","    for index, row in data_dictionary.iterrows():\n","        # Create a dictionary for the row\n","        row_data = {}\n","\n","        # Iterate over each column in the row\n","        for col_name in data_dictionary.columns:\n","            # Add the column name and value to the dictionary\n","            if pd.isna(row[col_name]):\n","                # If the value is empty, fill it with None\n","                row_data[col_name] = None\n","            else:\n","                row_data[col_name] = row[col_name]\n","\n","        # Check if the VariableName is in the required fields\n","        if row['VariableName'] in required_fields:\n","            row_data['Required'] = True\n","        else:\n","            row_data['Required'] = False\n","\n","        # mapping the data type from the data dictionary to json data types(used by frictionless)\n","        if row['DataType'] in data_type_mapping.keys():\n","          row_data['type'] = data_type_mapping[row['DataType']]\n","        else:\n","          row_data['type'] = \"any\"\n","\n","        row_data['format'] = \"default\"\n","\n","        # Append the row dictionary to the list of data\n","        fields.append(row_data)\n","\n","    return fields\n","\n","# Example usage:\n","required_fields = [\"Subject_ID\", \"Species\", \"Strain\", \"Animal_origin\", \"Age\", \"Weight\", \"Sex\", \"Group\", \"Laboratory\",\n","                   \"StudyLeader\", \"Published\", \"Exclusion_in_origin_study\", \"Exclusion_reason\", \"Cause_of_Death\",\n","                   \"Injury_type\", \"Injury_device\", \"Injury_level\", \"Injury_details\"]\n","\n","data_package_no = input(\"Enter odc-sci data package:\")\n","print(csv_file_path)\n","\n","csv_file_path = f\"odc-sci_{data_package_no}/odc-sci_{data_package_no}_dictionary.csv\"\n","\n","\n","fields_data = extract_fields_from_csv(csv_file_path, required_fields)\n","\n","\n","\n","# Print the extracted fields data\n","# for field in fields_data:\n","#     print(field)\n","\n","package = Package()\n","package.infer(f\"odc-sci_{data_package_no}/odc-sci_{data_package_no}.csv\")\n","package.infer(f\"odc-sci_{data_package_no}/odc-sci_{data_package_no}_dictionary.csv\")\n","\n","\n","# doi = \"10.34945/F5m88z\"           # 824\n","# doi = \"10.34945/F5730S\"             # 851\n","\n","# https://api.datacite.org/dois/10.34945/F5730S\n","doi = input(\"Enter DOI to create data package:\")\n","# We need to replace this with the DOI you want to retrieve\n","\n","\n","# Constructing the URL with the DOI variable\n","url = f\"https://api.datacite.org/dois/{doi}\"\n","\n","# HTTP GET request to the URL\n","response = requests.get(url)\n","\n","# Checkinng if the request was successful (status code 200)\n","if response.status_code == 200:\n","    # Parseing the JSON response, since the data is in json format\n","    data = response.json()\n","else:\n","    print(f\"Request failed with status code {response.status_code}\")\n","\n","\n","class attributeProcessor:\n","    def __init__(self, data):\n","        self.data = data.get('data', {}).get('attributes', {})\n","\n","    def get_abstract(self):\n","        try:\n","          abstract = self.data.get('descriptions', [{}])[0].get('description', \"\")\n","        except:\n","          abstract=\"\"\n","\n","        if len(abstract) < 1:\n","            return [{\n","                \"STUDY PURPOSE\": \"\",\n","                \"DATA COLLECTED\": \"\"\n","            }]\n","\n","        study_purpose_start = abstract.find(\"STUDY PURPOSE:\") + len(\"STUDY PURPOSE:\")\n","        data_collected_start = abstract.find(\"DATA COLLECTED:\") + len(\"DATA COLLECTED:\")\n","        data_usage_notes_start = abstract.find(\"DATA USAGE NOTES:\") + len(\"DATA USAGE NOTES:\")\n","\n","        study_purpose = abstract[study_purpose_start:data_collected_start - len(\"DATA COLLECTED:\") - 1]\n","        data_collected = abstract[data_collected_start:data_usage_notes_start - len(\"DATA USAGE NOTES:\") - 1]\n","        data_usage_notes = abstract[data_usage_notes_start:]\n","\n","        return [{\n","            \"STUDY PURPOSE\": study_purpose.strip(),\n","            \"DATA COLLECTED\": data_collected.strip()\n","        }]\n","\n","    def get_keywords(self):\n","        keyword_list = self.data.get('subjects', [])\n","        return [keyword['subject'] for keyword in keyword_list]\n","\n","    def get_contributors(self):\n","        contributors_list = self.data.get('creators', [])\n","        formatted_list = []\n","\n","        for contributor in contributors_list:\n","            formatted_item = f\"{contributor['name']} {', '.join(contributor['affiliation'])}\"\n","            formatted_list.append(formatted_item)\n","\n","        return formatted_list\n","\n","    def get_funding_acknowledgement(self):\n","\n","      funders_lst=[]\n","      try:\n","        funding_dict = self.data.get('fundingReferences', [{}])\n","      except:\n","        return[{\n","          'Name': \"\",\n","          'Identifier': \"\",\n","          'Type': \"\"\n","        }]\n","\n","      for funders in funding_dict:\n","        funder =  {\n","          'Name': funders.get('funderName', ''),\n","          'Identifier': funders.get('funderIdentifier', ''),\n","          'Type': funders.get('funderIdentifierType', '')\n","          }\n","        funders_lst.append(funder)\n","\n","      return funders_lst\n","\n","\n","    def get_title(self):\n","        return self.data.get('titles', [{}])[0].get('title', '')\n","\n","    def get_doi(self):\n","        return self.data.get('doi', '')\n","\n","\n","    def get_license(self):\n","\n","      license_lst=[]\n","      try:\n","        license_dict = self.data.get('rightsList', [{}])\n","      except:\n","        return[{\n","          'Name': \"\"\n","        }]\n","\n","      for licenses in license_dict:\n","        license =  {\n","          'Name': licenses.get('rights', '')\n","          }\n","        license_lst.append(license)\n","\n","      return license_lst\n","\n","    # def get_license(self):\n","    #     return [{\"Name\":self.data.get('rightsList', [{}])[0].get('rights', '')}]\n","\n","\n","\n","    # # adding other details-> meta data\n","\n","att_processor = attributeProcessor(data)\n","\n","package.descriptor[\"title\"] = att_processor.get_title()\n","package.descriptor[\"profile\"] = \"data-package\"\n","package.descriptor[\"DOI\"] = att_processor.get_doi()\n","package.descriptor[\"ABSTRACT\"] = att_processor.get_abstract()\n","package.descriptor[\"KEYWORDS\"] = att_processor.get_keywords()\n","package.descriptor[\"LICENSE\"] = att_processor.get_license()\n","package.descriptor[\"FUNDING AND ACKNOWLEDGEMENTS\"] = att_processor.get_funding_acknowledgement()\n","package.descriptor[\"CONTRIBUTORS\"] = att_processor.get_contributors()\n","\n","\n","# adding data schema details\n","package.descriptor['resources'][0]['schema']['fields'] = fields_data\n","\n","\n","\n","try:\n","  prefix = \"_\".join(data.get('data', {}).get('attributes', {}).get('identifiers',{})[0].get('identifier',{}).split(\":\"))\n","  file_name = prefix+\"_datapackage.zip\"\n","except:\n","  print(\"Error while generating filename, check data idenfifiers\")\n","\n","\n","\n","package.commit()\n","print(f\"Saving data package as {file_name}\")\n","package.save(file_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"A0lEAaZfN4Z9","executionInfo":{"status":"error","timestamp":1692826206840,"user_tz":420,"elapsed":2874,"user":{"displayName":"Sourabh Prakash","userId":"03936934707781620921"}},"outputId":"31d173c9-6293-4496-9745-743ec7dad66e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter odc-sci data package:851\n","odc-sci_851/odc-sci_851_dictionary.csv\n"]},{"output_type":"error","ename":"UnicodeDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-964c03adc6c4>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mfields_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_fields_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-91-964c03adc6c4>\u001b[0m in \u001b[0;36mextract_fields_from_csv\u001b[0;34m(csv_file_path, required_fields)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_fields_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Read the CSV file into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Create a list to store field data structures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_original_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         ) = self._infer_columns()\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Now self.columns has the set of columns that we will process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_infer_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_pos\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_buffered_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_for_bom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_row\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mScalar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mScalar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_next_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 \u001b[0morig_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m             \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x95 in position 1124: invalid start byte"]}]},{"cell_type":"code","source":["# doi = \"10.34945/F5m88z\"           # 824\n","doi = \"10.34945/F5730S\"             # 851"],"metadata":{"id":"AxpAGk1LSWOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["what is frictionless - intro, helpful links, integration with r and python\n","why we using it - validation\n"," why important with odc\n","desc of odc-frictionless data\n","\n","getting frictionless data via odc endpoint."],"metadata":{"id":"pEiCiOr3WGQD"},"execution_count":null,"outputs":[]}]}